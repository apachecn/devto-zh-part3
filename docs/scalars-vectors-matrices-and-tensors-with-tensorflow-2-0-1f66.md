# Tensorflow 2.0 ä¸­çš„æ ‡é‡ã€å‘é‡ã€çŸ©é˜µå’Œå¼ é‡

> åŸæ–‡ï¼š<https://dev.to/mmithrakumar/scalars-vectors-matrices-and-tensors-with-tensorflow-2-0-1f66>

**æ ‡é‡:**åªæ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—ã€‚ä¾‹å¦‚åªç”¨ä¸€ä¸ªæ•°å­—è¡¨ç¤ºçš„æ¸©åº¦ã€‚

**Vectors:** æ˜¯ä¸€ä¸ªæ•°å­—æ•°ç»„ã€‚è¿™äº›æ•°å­—æ˜¯æŒ‰é¡ºåºæ’åˆ—çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å…¶åœ¨è¯¥é¡ºåºä¸­çš„ç´¢å¼•æ¥è¯†åˆ«æ¯ä¸ªæ•°å­—ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå‘é‡çœ‹ä½œæ˜¯ç©ºé—´ä¸­çš„æ ‡è¯†ç‚¹ï¼Œæ¯ä¸ªå…ƒç´ ç»™å‡ºä¸åŒè½´ä¸Šçš„åæ ‡ã€‚ç®€å•æ¥è¯´ï¼ŒçŸ¢é‡æ˜¯ä¸€ä¸ªç®­å¤´ï¼Œå®ƒä»£è¡¨ä¸€ä¸ªæ—¢æœ‰å¤§å°åˆæœ‰æ–¹å‘çš„é‡ï¼Œç®­å¤´çš„é•¿åº¦ä»£è¡¨å¤§å°ï¼Œæ–¹å‘å‘Šè¯‰ä½ æ–¹å‘ã€‚ä¾‹å¦‚é£ï¼Œå®ƒæœ‰æ–¹å‘å’Œå¤§å°ã€‚

çŸ©é˜µæ˜¯ä¸€ä¸ª 2D æ•°ç»„ï¼Œæ‰€ä»¥æ¯ä¸ªå…ƒç´ éƒ½æœ‰ä¸¤ä¸ªç´¢å¼•æ¥æ ‡è¯†ï¼Œè€Œä¸æ˜¯åªæœ‰ä¸€ä¸ªã€‚å¦‚æœä¸€ä¸ªå®å€¼çŸ©é˜µ ***A*** çš„é«˜åº¦ä¸º *m* ï¼Œå®½åº¦ä¸º *n* ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¯´ a åœ¨ R^(m x n)ã€‚æˆ‘ä»¬å°†çŸ©é˜µçš„å…ƒç´ æ ‡è¯†ä¸º A_(mï¼Œn ),å…¶ä¸­ *m* è¡¨ç¤ºè¡Œï¼Œè€Œ *n* è¡¨ç¤ºåˆ—ã€‚

[![Scalars, Vectors, Matrices and Tensors](img/1701b9f1696e66396911fdacb6ce82bb.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--oTgfo1EL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201a.png)

**å¼ é‡:**åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæ’åˆ—åœ¨å…·æœ‰å¯å˜è½´æ•°çš„è§„åˆ™ç½‘æ ¼ä¸Šçš„ä¸€ç»„æ•°å­—ç§°ä¸ºå¼ é‡ã€‚æˆ‘ä»¬é€šè¿‡å†™ A_(iï¼Œjï¼Œk)æ¥è¯†åˆ«ä¸€ä¸ªå¼ é‡**T3A**åœ¨åæ ‡( *iï¼Œjï¼Œk* )çš„å…ƒç´ ã€‚ä½†æ˜¯ä¸ºäº†çœŸæ­£ç†è§£å¼ é‡ï¼Œæˆ‘ä»¬éœ€è¦æ‰©å±•æˆ‘ä»¬è®¤ä¸ºå‘é‡åªæ˜¯æœ‰å¤§å°å’Œæ–¹å‘çš„ç®­å¤´çš„æ–¹å¼ã€‚è¯·è®°ä½ï¼Œä¸€ä¸ªçŸ¢é‡å¯ä»¥ç”±ä¸‰ä¸ªåˆ†é‡è¡¨ç¤ºï¼Œå³ xã€y å’Œ z åˆ†é‡(åŸºæœ¬çŸ¢é‡)ã€‚å¦‚æœä½ æœ‰ä¸€æ”¯ç¬”å’Œä¸€å¼ çº¸ï¼Œè®©æˆ‘ä»¬åšä¸€ä¸ªå°å®éªŒï¼Œå°†ç¬”å‚ç›´æ”¾åœ¨çº¸ä¸Šï¼Œå€¾æ–œä¸€å®šè§’åº¦ï¼Œç„¶åä»é¡¶éƒ¨ç…§å°„å…‰çº¿ï¼Œä½¿ç¬”çš„é˜´å½±è½åœ¨çº¸ä¸Šï¼Œè¿™ä¸ªé˜´å½±ä»£è¡¨çŸ¢é‡â€œç¬”â€çš„ x åˆ†é‡ï¼Œä»çº¸åˆ°ç¬”å°–çš„é«˜åº¦æ˜¯ y åˆ†é‡ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç”¨è¿™äº›åˆ†é‡æ¥æè¿°å¼ é‡ï¼Œæƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ˜¯å°ç¬¬å®‰çº³Â·ç¼æ–¯æˆ–è€…ä¸€ä¸ªå¯»å®è€…ï¼Œä½ è¢«å›°åœ¨ä¸€ä¸ªç«‹æ–¹ä½“é‡Œï¼Œæœ‰ä¸‰ä¸ªç®­å¤´ä»ç«‹æ–¹ä½“çš„ä¸‰ä¸ªé¢(ä»£è¡¨ xï¼Œyï¼Œz è½´)é£å‘ä½ ğŸ˜¬, æˆ‘çŸ¥é“è¿™æ˜¯ä½ åœ¨è¿™ç§æƒ…å†µä¸‹æœ€ä¸å¯èƒ½æƒ³åˆ°çš„äº‹æƒ…ï¼Œä½†æ˜¯ä½ å¯ä»¥æŠŠè¿™ä¸‰ä¸ªç®­å¤´æƒ³è±¡æˆä»ç«‹æ–¹ä½“çš„ä¸‰ä¸ªé¢æŒ‡å‘ä½ çš„å‘é‡ï¼Œä½ å¯ä»¥ç”¨ xï¼Œy å’Œ z åˆ†é‡æ¥è¡¨ç¤ºè¿™äº›å‘é‡(ç®­å¤´),ç°åœ¨è¿™æ˜¯ä¸€ä¸ªæœ‰ 9 ä¸ªåˆ†é‡çš„ç§© 2 å¼ é‡(çŸ©é˜µ)ã€‚ è®°ä½è¿™æ˜¯ä¸€ä¸ªéå¸¸éå¸¸ç®€å•çš„å¼ é‡è§£é‡Šã€‚ä»¥ä¸‹æ˜¯å¼ é‡çš„è¡¨ç¤º:

[![Tensors](img/ce808882e4000a65cdec1fb50192d993.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--AZlkJBsY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201b.PNG)

æˆ‘ä»¬å¯ä»¥å°†çŸ©é˜µå½¼æ­¤ç›¸åŠ ï¼Œåªè¦å®ƒä»¬å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼Œåªéœ€å°†å®ƒä»¬ç›¸åº”çš„å…ƒç´ ç›¸åŠ å³å¯:

C = A + B å…¶ä¸­ C(Iï¼Œj)= A(Iï¼Œj)+B(Iï¼Œj)

å¦‚æœæ‚¨åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹æ–¹ç¨‹æœ‰å›°éš¾ï¼Œæ‚¨ä¹Ÿå¯ä»¥å®Œæ•´é˜…è¯» [Jupyter nbviewer](https://nbviewer.jupyter.org/github/adhiraiyan/DeepLearningWithTF2.0/blob/master/notebooks/02.00-Linear-Algebra.ipynb) ä¸­çš„ç« èŠ‚ã€‚å¦‚æœæ²¡æœ‰ï¼Œæˆ‘ä»¬ç»§ç»­ã€‚

åœ¨ tensorflow a:

*   ç§©ä¸º 0 çš„å¼ é‡æ˜¯æ ‡é‡
*   ç§© 1 å¼ é‡æ˜¯ä¸€ä¸ªå‘é‡
*   ç§© 2 å¼ é‡æ˜¯ä¸€ä¸ªçŸ©é˜µ
*   ç§© 3 å¼ é‡æ˜¯ä¸€ä¸ª 3-å¼ é‡
*   ç§© n å¼ é‡æ˜¯ n å¼ é‡

```
# let's create a ones 3x3 rank 2 tensor rank_2_tensor_A = tf.ones([3, 3], name='MatrixA')
print("3x3 Rank 2 Tensor A: \n{}\n".format(rank_2_tensor_A))

# let's manually create a 3x3 rank two tensor and specify the data type as float rank_2_tensor_B = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], name='MatrixB', dtype=tf.float32)
print("3x3 Rank 2 Tensor B: \n{}\n".format(rank_2_tensor_B))

# addition of the two tensors rank_2_tensor_C = tf.add(rank_2_tensor_A, rank_2_tensor_B, name='MatrixC')
print("Rank 2 Tensor C with shape={} and elements: \n{}".format(rank_2_tensor_C.shape, rank_2_tensor_C))

3x3 Rank 2 Tensor A:
[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]

3x3 Rank 2 Tensor B:
[[1. 2. 3.]
 [4. 5. 6.]
 [7. 8. 9.]]

Rank 2 Tensor C with shape=(3, 3) and elements:
[[ 2.  3.  4.]
 [ 5.  6.  7.]
 [ 8.  9. 10.]] 
```

Enter fullscreen mode Exit fullscreen mode

```
# Let's see what happens if the shapes are not the same two_by_three = tf.ones([2, 3])
try:
    incompatible_tensor = tf.add(two_by_three, rank_2_tensor_B)
except:
    print("""Incompatible shapes to add with two_by_three of shape {0} and 3x3 Rank 2 Tensor B of shape {1}
    """.format(two_by_three.shape, rank_2_tensor_B.shape))

Incompatible shapes to add with two_by_three of shape (2, 3) and 3x3 Rank 2 Tensor B of shape (3, 3) 
```

Enter fullscreen mode Exit fullscreen mode

æˆ‘ä»¬è¿˜å¯ä»¥å‘çŸ©é˜µæ·»åŠ ä¸€ä¸ªæ ‡é‡ï¼Œæˆ–è€…å°†çŸ©é˜µä¹˜ä»¥ä¸€ä¸ªæ ‡é‡ï¼Œåªéœ€å¯¹çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ æ‰§è¡Œè¯¥æ“ä½œ:

D = a.B + c å…¶ä¸­ D_(iï¼Œj) = a.B_(iï¼Œj) + c

```
# Create scalar a, c and Matrix B rank_0_tensor_a = tf.constant(2, name="scalar_a", dtype=tf.float32)
rank_2_tensor_B = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], name='MatrixB', dtype=tf.float32)
rank_0_tensor_c = tf.constant(3, name="scalar_c", dtype=tf.float32)

# multiplying aB multiply_scalar = tf.multiply(rank_0_tensor_a, rank_2_tensor_B)
# adding aB + c rank_2_tensor_D = tf.add(multiply_scalar, rank_0_tensor_c, name="MatrixD")

print("""Original Rank 2 Tensor B: \n{0} \n\nScalar a: {1}
Rank 2 Tensor for aB: \n{2} \n\nScalar c: {3} \nRank 2 Tensor D = aB + c: \n{4}
""".format(rank_2_tensor_B, rank_0_tensor_a, multiply_scalar, rank_0_tensor_c, rank_2_tensor_D))

Original Rank 2 Tensor B:
[[1. 2. 3.]
 [4. 5. 6.]
 [7. 8. 9.]]

Scalar a: 2.0
Rank 2 Tensor for aB:
[[ 2.  4.  6.]
 [ 8. 10. 12.]
 [14. 16. 18.]]

Scalar c: 3.0
Rank 2 Tensor D = aB + c:
[[ 5.  7.  9.]
 [11. 13. 15.]
 [17. 19. 21.]] 
```

Enter fullscreen mode Exit fullscreen mode

å¯¹çŸ©é˜µçš„ä¸€ä¸ªé‡è¦æ“ä½œæ˜¯**è½¬ç½®**ã€‚çŸ©é˜µçš„è½¬ç½®æ˜¯çŸ©é˜µåœ¨ä¸€æ¡å¯¹è§’çº¿ä¸Šçš„é•œåƒï¼Œè¿™æ¡å¯¹è§’çº¿å«åš**ä¸»å¯¹è§’çº¿**ã€‚æˆ‘ä»¬å°†çŸ©é˜µ ***A*** çš„è½¬ç½®è¡¨ç¤ºä¸º A^Tï¼Œå®šä¹‰å¦‚ä¸‹:A^T *(iï¼Œj) = A* (jï¼Œi)

```
# Creating a Matrix E rank_2_tensor_E = tf.constant([[1, 2, 3], [4, 5, 6]])
# Transposing Matrix E transpose_E = tf.transpose(rank_2_tensor_E, name="transposeE")

print("""Rank 2 Tensor E of shape: {0} and elements: \n{1}\n Transpose of Rank 2 Tensor E of shape: {2} and elements: \n{3}""".format(rank_2_tensor_E.shape, rank_2_tensor_E, transpose_E.shape, transpose_E))

Rank 2 Tensor E of shape: (2, 3) and elements:
[[1 2 3]
 [4 5 6]]

Transpose of Rank 2 Tensor E of shape: (3, 2) and elements:
[[1 4]
 [2 5]
 [3 6]] 
```

Enter fullscreen mode Exit fullscreen mode

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å…è®¸çŸ©é˜µå’Œå‘é‡ç›¸åŠ ï¼Œäº§ç”Ÿå¦ä¸€ä¸ªçŸ©é˜µï¼Œå…¶ä¸­ C_(iï¼Œj) = A_(iï¼Œj) + b_(j)ã€‚æ¢å¥è¯è¯´ï¼Œå‘é‡ *b* è¢«æ·»åŠ åˆ°çŸ©é˜µçš„æ¯ä¸€è¡Œã€‚è¿™ç§å°† *b* éšå¼å¤åˆ¶åˆ°å¤šä¸ªä½ç½®çš„æ–¹å¼è¢«ç§°ä¸º**å¹¿æ’­**

```
# Creating a vector b rank_1_tensor_b = tf.constant([[4.], [5.], [6.]])
# Broadcasting a vector b to a matrix A such that it yields a matrix F = A + b rank_2_tensor_F = tf.add(rank_2_tensor_A, rank_1_tensor_b, name="broadcastF")

print("""Rank 2 tensor A: \n{0}\n  \nRank 1 Tensor b: \n{1} \nRank 2 tensor F = A + b:\n{2}""".format(rank_2_tensor_A, rank_1_tensor_b, rank_2_tensor_F))

Rank 2 tensor A:
[[1. 1. 1.]
 [1. 1. 1.]
 [1. 1. 1.]]

Rank 1 Tensor b:
[[4.]
 [5.]
 [6.]]

Rank 2 tensor F = A + b:
[[5. 5. 5.]
 [6. 6. 6.]
 [7. 7. 7.]] 
```

Enter fullscreen mode Exit fullscreen mode

* * *

è¿™æ˜¯ã€Šç”¨ Tensorflow 2.0 è¿›è¡Œæ·±åº¦å­¦ä¹ ã€‹ä¸€ä¹¦ã€Šç”¨ Tensorflow 2.0 è¿›è¡Œçº¿æ€§ä»£æ•°ã€‹ä¸€ç« çš„ç¬¬äºŒèŠ‚ã€‚

æ‚¨å¯ä»¥é˜…è¯»æœ¬èŠ‚å’Œä»¥ä¸‹ä¸»é¢˜:

02.01 â€”æ ‡é‡ã€å‘é‡ã€çŸ©é˜µå’Œå¼ é‡
02.02 â€”ä¹˜æ³•çŸ©é˜µå’Œå‘é‡
02.03 â€”å•ä½çŸ©é˜µå’Œé€†çŸ©é˜µ
02.04 â€”çº¿æ€§ç›¸å…³å’Œè·¨åº¦
02.05 â€”èŒƒæ•°
02.06 â€”ç‰¹æ®Šç±»å‹çš„çŸ©é˜µå’Œå‘é‡
02.07 â€”ç‰¹å¾åˆ†è§£
02.08 â€”å¥‡å¼‚å€¼åˆ†è§£
02.09 â€”æ‘©å°”-å½­ç½—æ–¯ä¼ªé€†
02.02ã€‚

åœ¨[ç”¨ TF 2.0 æ·±åº¦å­¦ä¹ :02.00-çº¿æ€§ä»£æ•°](https://www.adhiraiyan.org/deeplearning/02.00-Linear-Algebra)ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œè·å¾—è¿™ç¯‡æ–‡ç« å’Œæœ¬ç« [å…¶ä½™éƒ¨åˆ†çš„ä»£ç ã€‚Google Colab å’Œ Jupyter Binder ä¸­ç¬”è®°æœ¬çš„é“¾æ¥åœ¨](https://github.com/adhiraiyan/DeepLearningWithTF2.0)[ç¬”è®°æœ¬](https://www.adhiraiyan.org/deeplearning/02.00-Linear-Algebra)çš„æœ«å°¾ã€‚