# å­¦ä¹ ä¸æ·±çš„æ—¶å°š MNIST

> åŸæ–‡ï¼š<https://dev.to/hydroweaver/fashion-mnist-with-not-so-deep-learning-16el>

[![MNIST](img/0a7aab2495ddbdeab5d5a6119296c95e.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--B1JktMMm--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/z9d3jxofhn8dai8ulv5s.png)

å—¨å¾·å¼—å…¹ï¼

è¿™æ˜¯ä¸€ç¯‡å…³äºä½¿ç”¨ä» Python æ·±åº¦å­¦ä¹ çš„ç¬¬ä¸€éƒ¨åˆ†è·å¾—çš„çŸ¥è¯†æ¥åˆ†ç±» T2 æ—¶å°š MNIST å›¾ç‰‡çš„æ–‡ç« ã€‚

è¿™å®é™…ä¸Šæ˜¯ MNIST æ•°å­—è¯†åˆ«å™¨çš„æ‰©å±•ï¼Œç”¨äºè¯†åˆ«ä¸åŒç§ç±»çš„å¯ç©¿æˆ´è®¾å¤‡ï¼Œå¤–å¥—ï¼Œè¡¬è¡«ï¼Œé‹å­ç­‰ã€‚

æ­£å¦‚ä½ ä»æ ‡é¢˜ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘æ²¡æœ‰ä½¿ç”¨ DL çš„æ›´æ·±å±‚éƒ¨åˆ†ï¼Œå³å·ç§¯ç¥ç»ç½‘ç»œï¼Œå¦ç‡åœ°è¯´ï¼Œæˆ‘åªæ˜¯å¼ºè¡Œè¿›è¡Œäº†å‡ æ¬¡ç»„åˆï¼Œç›´åˆ°æˆ‘åœ¨æµ‹è¯•æ•°æ®ä¸Šè·å¾—æœ€ä½³ç²¾åº¦ã€‚

æˆ‘ä½¿ç”¨äº†ä»¥ä¸‹å‡ ç§æ–¹æ³•çš„ç»„åˆï¼Œå¹¶é€‰æ‹©äº†æµ‹è¯•ç²¾åº¦æœ€é«˜çš„ä¸€ç§æ–¹æ³•:

1.  å¤šä¸ªéšè—å±‚
2.  éšè—å±‚ä¸­çš„å¤šä¸ªå•å…ƒç»„åˆ
3.  ç¬¬ä¸€å±‚å•å…ƒçš„å¤šé‡ç»„åˆ

æœ€ä½³æ¨¡å‹ä¸º 1 ä¸ªéšå±‚ 128 ä¸ªå•å…ƒï¼Œå¤–å±‚ 512 ä¸ªå•å…ƒï¼Œå‡†ç¡®ç‡ä¸º 89.04%ã€‚

ç„¶è€Œè¿™å¹¶ä¸æ˜¯åº”è¯¥åšçš„ï¼Œå› ä¸ºåœ¨ç°å®ä¸–ç•Œä¸­ï¼Œå¤„ç†çœŸæ­£çš„ã€å›°éš¾çš„ ML é—®é¢˜çš„èµ„æºæ˜¯æœ‰é™çš„ï¼ğŸ˜

### ä»£ç 

```
from keras import models
from keras import layers
from keras.datasets import fashion_mnist
import numpy as np
import matplotlib.pyplot as plt
from keras.utils import to_categorical, plot_model
import operator

(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()

def shape(arr):
    x = np.reshape(arr, (len(arr), 784))
    return x

#epochs e = 40

#prediction array eval_arr = {}
pred_arr = {}

#label summary label_list = {0: 'T-shirt/top', 1: 'Trouser', 2:'Pullover', 3:'Dress', 4:'Coat', 5:'Sandal', 6:'Shirt', 7:'Sneaker', 8:'Bag', 9:'Ankle boot'}

#path output_dir_model = r'C:\Users\karan.verma\.spyder-py3\deep-learning\models'

train_x_reshaped = shape(train_x).astype('float32')/255
train_y = to_categorical(train_y)
train_y = train_y.astype('float32')

test_x_reshaped = shape(test_x).astype('float32')/255
test_y = to_categorical(test_y)
test_y = test_y.astype('float32')

#take out validation data, 25% = 15,000 samples 
partial_train_x = train_x_reshaped[:int(len(train_x_reshaped)*0.75)]
partial_train_y = train_y[:int(len(train_y)*0.75)]

val_x = train_x_reshaped[int(len(train_x_reshaped)*0.75):]
val_y = train_y[int(len(train_y)*0.75):]

# run model with several different parameters 
#lyrs = [1, 2]
#units_out = [512, 256, 128, 64, 32, 16]
#units_in = [128, 64, 32, 16] 
lyrs = [1]
units_out = [512]
units_in = [128]

#make model for lyr in lyrs:
    for unit_out in units_out:
        for unit_in in units_in:

            print('Running model having %d hidden layers & %d units in each hidden layer and %d units in the outer layer' % (lyr, unit_in, unit_out))

            model = models.Sequential()
            model.add(layers.Dense(unit_out, activation='relu', input_shape=(784,)))

            for i in range(lyr):
                model.add(layers.Dense(unit_in, activation='relu'))

            model.add(layers.Dense(10, activation = 'sigmoid'))

            #compile model
            model.compile(optimizer = 'rmsprop',
                          loss = 'categorical_crossentropy',
                          metrics=['accuracy'])

            #model fit 
            history = model.fit(partial_train_x,
                                partial_train_y,
                                epochs = e,
                                batch_size=512,
                                validation_data=(val_x, val_y),
                                verbose = 1)

            acc_list = history.history
            fig, ax = plt.subplots(2,1, figsize=(20, 10))

            plt.subplot(211)
            plt.plot(np.arange(1, e+1), acc_list['loss'], label='Training Loss')
            plt.plot(np.arange(1, e+1), acc_list['val_loss'], label='Validation Loss')
            plt.title('Loss Graph')
            plt.xlabel('Epochs')
            plt.ylabel('Loss')
            plt.legend()

            plt.subplot(212)
            plt.plot(np.arange(1, e+1), acc_list['acc'], label='Training Acc')
            plt.plot(np.arange(1, e+1), acc_list['val_acc'], label='Validation Acc')
            plt.title('Accuracy Graph')
            plt.xlabel('Epochs')
            plt.ylabel('Accuracy')
            plt.legend()

            #plt.tight_layout()
            fig.savefig('{}/Model having %d hidden layers & %d units in each hidden layer and %d units in the outer layer.png'.format(output_dir_model) % (lyr, unit_in, unit_out))            
            plt.clf()

            eval_arr['Model having %d hidden layers & %d units in each hidden layer and %d units in the outer layer' % (lyr, unit_in, unit_out)] = model.evaluate(test_x_reshaped, test_y)
            pred_arr['Model having %d hidden layers & %d units in each hidden layer and %d units in the outer layer' % (lyr, unit_in, unit_out)]= np.argmax(model.predict(test_x_reshaped), axis=1)

#get best model from eval_arr best_model = {}
k = ''

for key, val in eval_arr.items():
    best_model[key] = val[1]

print('The best model is: {}'.format(max(best_model.items(), key=operator.itemgetter(1))))

#Building Prediction Pipeline
#('Model having 1 hidden layers & 128 units in each hidden layer and 512 units in the outer layer',0.8953) but it varies 
prediction = model.predict(test_x_reshaped)

print('Random samples from the test data: ')
fig, ax = plt.subplots(2, 3, figsize=(20, 10))
for i in range(1, 7):
        c = np.random.choice(len(test_x_reshaped))
        plt.subplot(2,3,i)
        plt.imshow(test_x[c])
        plt.title('Original {} & Predicted {}'.format(label_list[np.argmax(test_y[c])], label_list[np.argmax(prediction[c])])) 
```

### è¾“å‡ºå›¾å½¢

[![output](img/3d26b6c9d6fb7d0d6220857f32733913.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--Z-g29eNd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/vyzu3nrdly9q8wqfvni5.png)

### å…³é”®è¦ç‚¹

1.  å¦‚æœä½ æ­£åœ¨å¤„ç†ä¸€ä¸ª ML é—®é¢˜ï¼ŒèŠ±ç‚¹æ—¶é—´ç†è§£å›¾è¡¨ï¼Œå¦åˆ™å®ƒæ²¡æœ‰ä»»ä½•æ„ä¹‰
2.  å°è¯•ä¹¦æœ¬/æ•™ç¨‹ä¹‹å¤–çš„é—®é¢˜ã€‚
3.  åœ¨æ²¡æœ‰ä»»ä½•æŒ‡å¯¼çš„æƒ…å†µä¸‹ï¼Œè‡ªå·±å»å®ç°ä¸€äº›ä¸œè¥¿ï¼Œè¿™ä¼šè®©ä½ çš„å¤§è„‘å—ä¼¤ï¼Œä½†æ˜¯ä½ ä¼šå­¦ä¼šçš„ã€‚
4.  é™·å…¥å¤šæ¬¡ï¼Œè°·æ­Œå®ƒï¼Œä½¿å…¶å·¥ä½œï¼Œå¹¶å‰è¿›åˆ°æœ¬ä¹¦çš„ç¬¬ 2 èŠ‚ï¼ğŸ˜‚

é“¾æ¥åˆ°[ä»£ç ](https://github.com/hydroweaver/deep-learning/blob/master/fashion_mnist_trial.py)ã€‚

* *ç¼–è¾‘:æ€»æ˜¯å¿˜è®°ï¼Œä½†æ‰€æœ‰çš„é—®é¢˜ï¼Œè¯„è®ºï¼Œæ‰¹è¯„æ˜¯ç«­è¯šæ¬¢è¿ï¼ğŸ˜ƒ

ç¥ä½ æ„‰å¿«ï¼