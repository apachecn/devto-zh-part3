# ä»é›¶å¼€å§‹å›å½’-è‘¡è„é…’è´¨é‡é¢„æµ‹

> åŸæ–‡ï¼š<https://dev.to/apoorvadave/regression-from-scratch---wine-quality-prediction-3245>

åœ¨æˆ‘ä»¬ä¹‹å‰çš„å¸–å­ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†æœºå™¨å­¦ä¹ å’Œå›å½’ç±»å‹çš„åŸºç¡€çŸ¥è¯†ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†åšæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®ã€‚è¿™å°†ä¸ºæˆ‘ä»¬å¦‚ä½•åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šå®ç°å›å½’æä¾›ä¸€ä¸ªæ€è·¯ã€‚è®¾ç½®ã€ç†è§£å’Œç¼–ç åªéœ€è¦ä¸€ä¸ªå°æ—¶ã€‚æ‰€ä»¥è®©æˆ‘ä»¬å¼€å§‹å§ï¼ğŸ˜ƒ

[![ml1](img/90923b3b30ac92880b87ab280d19c643.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--MttaOcHF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/gle5qxtt2exd3skg15d7.jpeg)

è¿™é‡Œçš„ä»»åŠ¡æ˜¯ç»™å®šä¸€ç»„ç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œåœ¨ 0-10 çš„èŒƒå›´å†…é¢„æµ‹çº¢é…’çš„è´¨é‡ã€‚æˆ‘å·²ç»ç”¨çº¿æ€§å›å½’æŠŠå®ƒä½œä¸ºä¸€ä¸ªå›å½’é—®é¢˜è§£å†³äº†ã€‚

ä½¿ç”¨çš„æ•°æ®é›†æ˜¯æ¥è‡ª UCI æœºå™¨å­¦ä¹ çŸ¥è¯†åº“çš„è‘¡è„é…’è´¨é‡æ•°æ®é›†ã€‚æ‚¨å¯ä»¥åœ¨æ­¤æŸ¥çœ‹æ•°æ®é›†

è¾“å…¥å˜é‡ä¸ºå›ºå®šé…¸åº¦ã€æŒ¥å‘æ€§é…¸åº¦ã€æŸ æª¬é…¸ã€æ®‹ç³–ã€æ°¯åŒ–ç‰©ã€æ¸¸ç¦»äºŒæ°§åŒ–ç¡«ã€æ€»äºŒæ°§åŒ–ç¡«ã€å¯†åº¦ã€pHã€ç¡«é…¸ç›ã€é…’ç²¾ã€‚å¹¶ä¸”è¾“å‡ºå˜é‡(åŸºäºæ„Ÿå®˜æ•°æ®)æ˜¯è´¨é‡(å¾—åˆ†åœ¨ 0 åˆ° 10 ä¹‹é—´)ã€‚ä¸‹é¢æ˜¯æ•°æ®é›†å‰ 5 è¡Œçš„å±å¹•æˆªå›¾ã€‚

[![ml3](img/c0a1b114f83c6ef1b417c07f1fd4c908.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--D7-7UuZj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/tja0ich0q4nmsctd6h7p.png) 

<figure>

<figcaption>å‰ 5 è¡Œè‘¡è„é…’è´¨é‡æ•°æ®é›†</figcaption>

</figure>

## ä¾èµ–å…³ç³»

ä»£ç æ˜¯ç”¨ python å†™çš„ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¯·ä½¿ç”¨ pip å®‰è£…ä»¥ä¸‹åº“ã€‚

1.  ç†ŠçŒ«:pip å®‰è£…ç†ŠçŒ«
2.  matplotlib: pip å®‰è£… matplotlib
3.  numpy: pip å®‰è£… numpy
4.  scikit-learn: pip å®‰è£… scikit-learn

å°±æ˜¯è¿™æ ·ï¼ä½ å·²ç»å®Œæˆä¸€åŠäº†ğŸ˜„ã€‚æ¥ä¸‹æ¥ï¼ŒæŒ‰ç…§ä¸‹é¢çš„æ­¥éª¤ï¼Œä»¥å»ºç«‹ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹åœ¨ä»»ä½•æ—¶å€™ï¼

## æ¥è¿‘

åˆ›å»ºä¸€ä¸ªæ–°çš„ IPython ç¬”è®°æœ¬ï¼Œæ’å…¥ä¸‹é¢çš„ä»£ç æ¥å¯¼å…¥å¿…è¦çš„æ¨¡å—ã€‚å¦‚æœæ‚¨é‡åˆ°ä»»ä½•é”™è¯¯ï¼Œè¯·ä½¿ç”¨ pip å®‰è£…å¿…è¦çš„è½¯ä»¶åŒ…ã€‚

```
import pandas as pd 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression 
from sklearn import metrics 
import matplotlib.pyplot as plt 
import numpy as np 
import seaborn as sns 
```

Enter fullscreen mode Exit fullscreen mode

ä½¿ç”¨ pandas å°†æ•°æ®è¯»å…¥æ•°æ®å¸§ã€‚è¦æ£€æŸ¥æ•°æ®é›†çš„å‰ 5 è¡Œï¼Œè¯·ä½¿ç”¨`df.head()`

```
df = pd.read_csv('winequality-red.csv')
df.head() 
```

Enter fullscreen mode Exit fullscreen mode

ä½¿ç”¨`corr()`
æŸ¥æ‰¾æ•°æ®é›†å„å±æ€§ä¹‹é—´çš„ç›¸å…³æ€§

```
# there are no categorical variables. each feature is a number. Regression problem. 
# Given the set of values for features, we have to predict the quality of wine. 
# finding correlation of each feature with our target variable - quality correlations = df.corr()['quality'].drop('quality')
print(correlations) 
```

Enter fullscreen mode Exit fullscreen mode

[![ml3](img/4eaf1f775ff4cfb5f21958b90709e22d.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--7iVxIXD4--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/j4g5z4hh6tx657w1w162.png) 

<figure>

<figcaption>å„å±æ€§ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§â€”è´¨é‡</figcaption>

</figure>

è¦ç»˜åˆ¶çƒ­å›¾å¹¶è·å¾—è¯¦ç»†çš„å…³è”å›¾ï¼Œè¯·æ’å…¥ä»¥ä¸‹ä»£ç ã€‚

```
sns.heatmap(df.corr())
plt.show() 
```

Enter fullscreen mode Exit fullscreen mode

[![ml4](img/2686602ceaf2d470feae8f4c3e76df88.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--xJw_b8dM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/x2k2axmew1uj85j2q8hk.png) 

<figure>

<figcaption>çƒ­å›¾</figcaption>

</figure>

å®šä¹‰ä¸€ä¸ªå‡½æ•°`get_features()`ï¼Œè¯¥å‡½æ•°ä»…è¾“å‡ºç›¸å…³æ€§é«˜äºé˜ˆå€¼çš„é‚£äº›ç‰¹å¾(ä½œä¸ºè¾“å…¥å‚æ•°ä¼ é€’ç»™å‡½æ•°)ã€‚

```
def get_features(correlation_threshold):
    abs_corrs = correlations.abs()
    high_correlations = abs_corrs
    [abs_corrs > correlation_threshold].index.values.tolist()
    return high_correlations 
```

Enter fullscreen mode Exit fullscreen mode

åˆ›å»ºä¸¤ä¸ªå‘é‡ï¼Œ`x`åŒ…å«è¾“å…¥ç‰¹å¾ï¼Œ`y`åŒ…å«è´¨é‡å˜é‡ã€‚åœ¨`x`ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°äº†é™¤æ®‹ç³–ä»¥å¤–çš„æ‰€æœ‰ç‰¹å¾ã€‚å¦‚æœä½ æ„¿æ„ï¼Œé˜ˆå€¼å¯ä»¥å¢åŠ ã€‚

```
# taking features with correlation more than 0.05 as input x and quality as target variable y features = get_features(0.05) 
print(features) 
x = df[features] 
y = df['quality'] 
```

Enter fullscreen mode Exit fullscreen mode

ä½¿ç”¨`train_test_split`åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•é›†ã€‚25%çš„æ•°æ®ç”¨äºæµ‹è¯•ï¼Œ75%ç”¨äºè®­ç»ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨`x_train.shape`
æ£€æŸ¥æ•°æ®é›†çš„å¤§å°

```
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=3) 
```

Enter fullscreen mode Exit fullscreen mode

ä¸€æ—¦åˆ›å»ºäº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå°±è¯¥æ„å»ºçº¿æ€§å›å½’æ¨¡å‹äº†ã€‚æ‚¨å¯ä»¥ç®€å•åœ°ä½¿ç”¨å†…ç½®å‡½æ•°æ¥åˆ›å»ºæ¨¡å‹ï¼Œç„¶åæ ¹æ®è®­ç»ƒæ•°æ®è¿›è¡Œæ‹Ÿåˆã€‚ä¸€æ—¦è®­ç»ƒå®Œæ¯•ï¼Œ`coef_`ç»™å‡ºæ¯ä¸ªç‰¹å¾çš„ç³»æ•°å€¼ã€‚

```
# fitting linear regression to training data regressor = LinearRegression()
regressor.fit(x_train,y_train)
# this gives the coefficients of the 10 features selected above. 
print(regressor.coef_) 
```

Enter fullscreen mode Exit fullscreen mode

ç”¨è¿™ä¸ªæ¨¡å‹é¢„æµ‹è‘¡è„é…’çš„è´¨é‡ï¼Œç”¨`predict()`ã€‚

```
train_pred = regressor.predict(x_train)
print(train_pred)
test_pred = regressor.predict(x_test) 
print(test_pred) 
```

Enter fullscreen mode Exit fullscreen mode

è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‡æ–¹æ ¹è¯¯å·®ã€‚å‡æ–¹æ ¹è¯¯å·®(RMSE)æ˜¯æ¨¡å‹é¢„æµ‹å€¼(æ ·æœ¬å€¼å’Œæ€»ä½“å€¼)ä¸å®é™…è§‚å¯Ÿå€¼ä¹‹é—´å·®å¼‚çš„å¸¸ç”¨åº¦é‡ã€‚å¦‚æœæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¥½çš„æ¨¡å‹ï¼Œé‚£ä¹ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ RMSE åº”è¯¥éå¸¸ç›¸ä¼¼ã€‚å¦‚æœæµ‹è¯•é›†çš„ RMSE æ¯”è®­ç»ƒé›†çš„é«˜å¾—å¤šï¼Œå¾ˆå¯èƒ½æˆ‘ä»¬ä¸¥é‡åœ°è¿‡åº¦æ‹Ÿåˆäº†æ•°æ®ã€‚

```
# calculating rmse train_rmse = mean_squared_error(train_pred, y_train) ** 0.5
print(train_rmse)
test_rmse = mean_squared_error(test_pred, y_test) ** 0.5
print(test_rmse)
# rounding off the predicted values for test set predicted_data = np.round_(test_pred)
print(predicted_data)
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, test_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, test_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, test_pred)))
# displaying coefficients of each feature coeffecients = pd.DataFrame(regressor.coef_,features) coeffecients.columns = ['Coeffecient'] 
print(coeffecients) 
```

Enter fullscreen mode Exit fullscreen mode

[![ml5](img/9cae567bd2721078147a5aa02091b029.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--xdaCEmzc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/lcpcyoncut1780nu12b1.png) 

<figure>

<figcaption>å„ç‰¹å¾çš„ç³»æ•°</figcaption>

</figure>

***è¿™äº›æ•°å­—æ„å‘³ç€ï¼Œåœ¨æ‰€æœ‰å…¶ä»–ç‰¹å¾ä¸å˜çš„æƒ…å†µä¸‹ï¼Œç¡«é…¸ç›æ¯å¢åŠ  1 ä¸ªå•ä½ï¼Œè‘¡è„é…’çš„è´¨é‡å°±ä¼šå¢åŠ  0.8ï¼Œå…¶ä»–ç‰¹å¾ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
åœ¨å…¶ä»–ç‰¹å¾ä¸å˜çš„æƒ…å†µä¸‹ï¼ŒæŒ¥å‘æ€§é…¸åº¦æ¯å¢åŠ  1 ä¸ªå•ä½ï¼Œè‘¡è„é…’è´¨é‡å°±ä¼šä¸‹é™ 0.99ï¼Œå…¶ä»–ç‰¹å¾ä¹Ÿæ˜¯å¦‚æ­¤ã€‚***

å› æ­¤ï¼Œé€šè¿‡å‡ è¡Œä»£ç ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ„å»ºä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹æ¥é¢„æµ‹è‘¡è„é…’çš„è´¨é‡ï¼Œå¯¹äºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ŒRMSE å¾—åˆ†åˆ†åˆ«ä¸º**0.65 å’Œ 0.63ã€‚è¿™åªæ˜¯ä¸€ä¸ªå¸®åŠ©ä½ å¼€å§‹å›å½’çš„æƒ³æ³•ã€‚æ‚¨å¯ä»¥å°è¯•é˜ˆå€¼ã€å…¶ä»–å›å½’æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥å°è¯•ç‰¹å¾å·¥ç¨‹ğŸ˜ã€‚**

è¦è·å¾—å®Œæ•´çš„ä»£ç ï¼Œè¯·ä½¿ç”¨è¿™ä¸ª[é“¾æ¥](https://github.com/apoorva-dave/WineQualityPrediction)åˆ°æˆ‘çš„åº“ã€‚æ•°æ®é›†ä¹Ÿè¢«ä¸Šä¼ :)å…‹éš†å­˜å‚¨åº“å¹¶è¿è¡Œç¬”è®°æœ¬æ¥æŸ¥çœ‹ç»“æœã€‚

ä¸‹ä¸€ç¯‡æ–‡ç« å°†æ˜¯å…³äºåˆ†ç±»å’Œä¸€ä¸ªç±»ä¼¼çš„å°é¡¹ç›®ã€‚æ•¬è¯·å…³æ³¨æ›´å¤šå†…å®¹ï¼åœ¨é‚£ä¹‹å‰ï¼Œç¥ä½ å­¦ä¹ æ„‰å¿«ğŸ˜¸